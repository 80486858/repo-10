debug:
  accelerator: cpu
  limit_train_batches: 10
  limit_val_batches: 10
  log_every_n_steps: 1
  max_epochs: 2
experiment:
  accelerator: gpu
  strategy: ddp_find_unused_parameters_true
generic:
  min_epochs: 15
  max_epochs: 100
callbacks:
  - class_path: pytorch_lightning.callbacks.EarlyStopping
    init_args:
      patience: 5
      monitor: val.total_loss
      mode: min
      verbose: True
      check_finite: False
  - class_path: pytorch_lightning.callbacks.ModelCheckpoint
    init_args:
      monitor: val.total_loss
      save_top_k: 3
  - class_path: matsciml.lightning.callbacks.GradientCheckCallback
  - class_path: matsciml.lightning.callbacks.SAM
loggers:
  - class_path: pytorch_lightning.loggers.CSVLogger # can omit init_args['save_dir'] for auto directory
